/root/tecGPT
dataset : GIMtec
mode : ori
device : cuda
model : GWN
cuda : True
val_ratio : 0.1
test_ratio : 0.1
lag : 12
horizon : 12
num_nodes : 5183
tod : False
normalizer : tec01
column_wise : False
default_graph : True
input_base_dim : 1
input_extra_dim : 2
output_dim : 1
embed_dim : 16
embed_dim_spa : 4
hidden_dim : 64
HS : 10
HT : 16
HT_Tem : 8
num_route : 2
mask_ratio : 0.25
ada_mask_ratio : 1.0
ada_type : all
loss_func : mask_mae
seed : 12
batch_size : 192
epochs : 1
lr_init : 0.003
lr_decay : True
lr_decay_rate : 0.3
lr_decay_step : 25, 50, 75
early_stop : True
early_stop_patience : 25
change_epoch : 5
up_epoch : 6, 8
grad_norm : True
max_grad_norm : 5
debug : False
debug_max_steps : 1000
real_value : False
optimizer : adam
weight_decay : 0.0
scheduler : none
plateau_factor : 0.9
plateau_patience : 20
plateau_threshold : 1e-05
plateau_threshold_mode : abs
plateau_cooldown : 10
min_lr : 0.0
cosine_t_max : 100
eta_min_factor : 0.01
grad_clip : 0.0
early_stop_min_delta : 0.0
accumulate_steps : 2
amp : True
seed_mode : True
xavier : False
load_pretrain_path : /GPTST_ada.pth
save_pretrain_path : new_pretrain_model.pth
init_from : 
stride_horizon : False
prefix_boundary : True
year_split : True
target_model : generic
graph_tag : grid8
use_pinn : True
lambda_phys : 0.2
use_diffusion : True
use_drivers : True
use_adv : True
rot_cap : 0.5
roti_cap_scale : 0.7
kappa_nd : 0.05
tec_ref : 50.0
t_ref_sec : 7200.0
mae_thresh : None
mape_thresh : 0.001
log_dir : ./
log_step : 20
plot : False
save_json : False
json_name : eval_results.json
==========
batch_size : 64
epochs : 100
lr_init : 0.003
lr_decay : True
lr_decay_rate : 0.3
lr_decay_step : 25, 50, 75
early_stop : True
early_stop_patience : 25
grad_norm : True
max_grad_norm : 5
debug : False
real_value : False
num_nodes : 5183
input_window : 12
output_window : 12
output_dim : 1
dropout : 0.3
blocks : 4
layers : 2
gcn_bool : True
addaptadj : True
adjtype : doubletransition
randomadj : True
aptonly : False
kernel_size : 2
nhid : 32
residual_channels : 32
dilation_channels : 32
graph_tag : grid8
adj_model : 
seed : 12
seed_mode : True
xavier : False
loss_func : mask_mae
filepath : ../data/GIMtec/
filename : GIMtec
adj_mx : [[1. 1. 0. ... 0. 0. 0.]
 [1. 1. 1. ... 0. 0. 0.]
 [0. 1. 1. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 1. 1. 0.]
 [0. 0. 0. ... 1. 1. 1.]
 [0. 0. 0. ... 0. 1. 1.]]
mode:  ori   model:  GWN   dataset:  GIMtec   load_pretrain_path:  /GPTST_ada.pth   save_pretrain_path:  new_pretrain_model.pth
*****************Model Parameter*****************
predictor.nodevec1 torch.Size([5183, 10]) True
predictor.nodevec2 torch.Size([10, 5183]) True
predictor.filter_convs.0.weight torch.Size([32, 32, 1, 2]) True
predictor.filter_convs.0.bias torch.Size([32]) True
predictor.filter_convs.1.weight torch.Size([32, 32, 1, 2]) True
predictor.filter_convs.1.bias torch.Size([32]) True
predictor.filter_convs.2.weight torch.Size([32, 32, 1, 2]) True
predictor.filter_convs.2.bias torch.Size([32]) True
predictor.filter_convs.3.weight torch.Size([32, 32, 1, 2]) True
predictor.filter_convs.3.bias torch.Size([32]) True
predictor.filter_convs.4.weight torch.Size([32, 32, 1, 2]) True
predictor.filter_convs.4.bias torch.Size([32]) True
predictor.filter_convs.5.weight torch.Size([32, 32, 1, 2]) True
predictor.filter_convs.5.bias torch.Size([32]) True
predictor.filter_convs.6.weight torch.Size([32, 32, 1, 2]) True
predictor.filter_convs.6.bias torch.Size([32]) True
predictor.filter_convs.7.weight torch.Size([32, 32, 1, 2]) True
predictor.filter_convs.7.bias torch.Size([32]) True
predictor.gate_convs.0.weight torch.Size([32, 32, 1, 2]) True
predictor.gate_convs.0.bias torch.Size([32]) True
predictor.gate_convs.1.weight torch.Size([32, 32, 1, 2]) True
predictor.gate_convs.1.bias torch.Size([32]) True
predictor.gate_convs.2.weight torch.Size([32, 32, 1, 2]) True
predictor.gate_convs.2.bias torch.Size([32]) True
predictor.gate_convs.3.weight torch.Size([32, 32, 1, 2]) True
predictor.gate_convs.3.bias torch.Size([32]) True
predictor.gate_convs.4.weight torch.Size([32, 32, 1, 2]) True
predictor.gate_convs.4.bias torch.Size([32]) True
predictor.gate_convs.5.weight torch.Size([32, 32, 1, 2]) True
predictor.gate_convs.5.bias torch.Size([32]) True
predictor.gate_convs.6.weight torch.Size([32, 32, 1, 2]) True
predictor.gate_convs.6.bias torch.Size([32]) True
predictor.gate_convs.7.weight torch.Size([32, 32, 1, 2]) True
predictor.gate_convs.7.bias torch.Size([32]) True
predictor.residual_convs.0.weight torch.Size([32, 32, 1, 1]) True
predictor.residual_convs.0.bias torch.Size([32]) True
predictor.residual_convs.1.weight torch.Size([32, 32, 1, 1]) True
predictor.residual_convs.1.bias torch.Size([32]) True
predictor.residual_convs.2.weight torch.Size([32, 32, 1, 1]) True
predictor.residual_convs.2.bias torch.Size([32]) True
predictor.residual_convs.3.weight torch.Size([32, 32, 1, 1]) True
predictor.residual_convs.3.bias torch.Size([32]) True
predictor.residual_convs.4.weight torch.Size([32, 32, 1, 1]) True
predictor.residual_convs.4.bias torch.Size([32]) True
predictor.residual_convs.5.weight torch.Size([32, 32, 1, 1]) True
predictor.residual_convs.5.bias torch.Size([32]) True
predictor.residual_convs.6.weight torch.Size([32, 32, 1, 1]) True
predictor.residual_convs.6.bias torch.Size([32]) True
predictor.residual_convs.7.weight torch.Size([32, 32, 1, 1]) True
predictor.residual_convs.7.bias torch.Size([32]) True
predictor.skip_convs.0.weight torch.Size([256, 32, 1, 1]) True
predictor.skip_convs.0.bias torch.Size([256]) True
predictor.skip_convs.1.weight torch.Size([256, 32, 1, 1]) True
predictor.skip_convs.1.bias torch.Size([256]) True
predictor.skip_convs.2.weight torch.Size([256, 32, 1, 1]) True
predictor.skip_convs.2.bias torch.Size([256]) True
predictor.skip_convs.3.weight torch.Size([256, 32, 1, 1]) True
predictor.skip_convs.3.bias torch.Size([256]) True
predictor.skip_convs.4.weight torch.Size([256, 32, 1, 1]) True
predictor.skip_convs.4.bias torch.Size([256]) True
predictor.skip_convs.5.weight torch.Size([256, 32, 1, 1]) True
predictor.skip_convs.5.bias torch.Size([256]) True
predictor.skip_convs.6.weight torch.Size([256, 32, 1, 1]) True
predictor.skip_convs.6.bias torch.Size([256]) True
predictor.skip_convs.7.weight torch.Size([256, 32, 1, 1]) True
predictor.skip_convs.7.bias torch.Size([256]) True
predictor.bn.0.weight torch.Size([32]) True
predictor.bn.0.bias torch.Size([32]) True
predictor.bn.1.weight torch.Size([32]) True
predictor.bn.1.bias torch.Size([32]) True
predictor.bn.2.weight torch.Size([32]) True
predictor.bn.2.bias torch.Size([32]) True
predictor.bn.3.weight torch.Size([32]) True
predictor.bn.3.bias torch.Size([32]) True
predictor.bn.4.weight torch.Size([32]) True
predictor.bn.4.bias torch.Size([32]) True
predictor.bn.5.weight torch.Size([32]) True
predictor.bn.5.bias torch.Size([32]) True
predictor.bn.6.weight torch.Size([32]) True
predictor.bn.6.bias torch.Size([32]) True
predictor.bn.7.weight torch.Size([32]) True
predictor.bn.7.bias torch.Size([32]) True
predictor.gconv.0.mlp.mlp.weight torch.Size([32, 224, 1, 1]) True
predictor.gconv.0.mlp.mlp.bias torch.Size([32]) True
predictor.gconv.1.mlp.mlp.weight torch.Size([32, 224, 1, 1]) True
predictor.gconv.1.mlp.mlp.bias torch.Size([32]) True
predictor.gconv.2.mlp.mlp.weight torch.Size([32, 224, 1, 1]) True
predictor.gconv.2.mlp.mlp.bias torch.Size([32]) True
predictor.gconv.3.mlp.mlp.weight torch.Size([32, 224, 1, 1]) True
predictor.gconv.3.mlp.mlp.bias torch.Size([32]) True
predictor.gconv.4.mlp.mlp.weight torch.Size([32, 224, 1, 1]) True
predictor.gconv.4.mlp.mlp.bias torch.Size([32]) True
predictor.gconv.5.mlp.mlp.weight torch.Size([32, 224, 1, 1]) True
predictor.gconv.5.mlp.mlp.bias torch.Size([32]) True
predictor.gconv.6.mlp.mlp.weight torch.Size([32, 224, 1, 1]) True
predictor.gconv.6.mlp.mlp.bias torch.Size([32]) True
predictor.gconv.7.mlp.mlp.weight torch.Size([32, 224, 1, 1]) True
predictor.gconv.7.mlp.mlp.bias torch.Size([32]) True
predictor.start_conv.weight torch.Size([32, 1, 1, 1]) True
predictor.start_conv.bias torch.Size([32]) True
predictor.end_conv_1.weight torch.Size([512, 256, 1, 1]) True
predictor.end_conv_1.bias torch.Size([512]) True
2025-09-25 12:30: Experiment log path in: /root/tecGPT/Output/GIMtec/GWN
2025-09-25 12:30: Command: python Run.py -dataset GIMtec -model GWN -mode ori -use_pinn True -lambda_phys 0.2 -use_drivers True -use_adv True -year_split True -epochs 1 -batch_size 192 -accumulate_steps 2 -scheduler none -amp True
2025-09-25 12:30: Torch: 2.7.0+cu128  CUDA: True
2025-09-25 12:30: GPU: NVIDIA H800 PCIe
2025-09-25 12:30: CUDA_VISIBLE_DEVICES=None
2025-09-25 12:30: HS: 10
2025-09-25 12:30: HT: 16
2025-09-25 12:30: HT_Tem: 8
2025-09-25 12:30: accumulate_steps: 2
2025-09-25 12:30: ada_mask_ratio: 1.0
2025-09-25 12:30: ada_type: all
2025-09-25 12:30: amp: True
2025-09-25 12:30: batch_size: 192
2025-09-25 12:30: change_epoch: 5
2025-09-25 12:30: cmdline: python Run.py -dataset GIMtec -model GWN -mode ori -use_pinn True -lambda_phys 0.2 -use_drivers True -use_adv True -year_split True -epochs 1 -batch_size 192 -accumulate_steps 2 -scheduler none -amp True
2025-09-25 12:30: column_wise: False
2025-09-25 12:30: cosine_t_max: 100
2025-09-25 12:30: cuda: True
2025-09-25 12:30: dataset: GIMtec
2025-09-25 12:30: debug: False
2025-09-25 12:30: debug_max_steps: 1000
2025-09-25 12:30: default_graph: True
2025-09-25 12:30: device: cuda
2025-09-25 12:30: early_stop: True
2025-09-25 12:30: early_stop_min_delta: 0.0
2025-09-25 12:30: early_stop_patience: 25
2025-09-25 12:30: embed_dim: 16
2025-09-25 12:30: embed_dim_spa: 4
2025-09-25 12:30: epochs: 1
2025-09-25 12:30: eta_min_factor: 0.01
2025-09-25 12:30: grad_clip: 0.0
2025-09-25 12:30: grad_norm: True
2025-09-25 12:30: graph_tag: grid8
2025-09-25 12:30: hidden_dim: 64
2025-09-25 12:30: horizon: 12
2025-09-25 12:30: init_from: 
2025-09-25 12:30: input_base_dim: 1
2025-09-25 12:30: input_extra_dim: 2
2025-09-25 12:30: interval: 120
2025-09-25 12:30: json_name: eval_results.json
2025-09-25 12:30: kappa_nd: 0.05
2025-09-25 12:30: lag: 12
2025-09-25 12:30: lambda_phys: 0.2
2025-09-25 12:30: load_pretrain_path: /GPTST_ada.pth
2025-09-25 12:30: log_dir: /root/tecGPT/Output/GIMtec/GWN
2025-09-25 12:30: log_step: 20
2025-09-25 12:30: loss_func: mask_mae
2025-09-25 12:30: lr_decay: True
2025-09-25 12:30: lr_decay_rate: 0.3
2025-09-25 12:30: lr_decay_step: 25, 50, 75
2025-09-25 12:30: lr_init: 0.003
2025-09-25 12:30: mae_thresh: None
2025-09-25 12:30: mape_thresh: 0.001
2025-09-25 12:30: mask_ratio: 0.25
2025-09-25 12:30: max_grad_norm: 5
2025-09-25 12:30: min_lr: 0.0
2025-09-25 12:30: mode: ori
2025-09-25 12:30: model: GWN
2025-09-25 12:30: normalizer: tec01
2025-09-25 12:30: num_nodes: 5183
2025-09-25 12:30: num_route: 2
2025-09-25 12:30: optimizer: adam
2025-09-25 12:30: output_dim: 1
2025-09-25 12:30: plateau_cooldown: 10
2025-09-25 12:30: plateau_factor: 0.9
2025-09-25 12:30: plateau_patience: 20
2025-09-25 12:30: plateau_threshold: 1e-05
2025-09-25 12:30: plateau_threshold_mode: abs
2025-09-25 12:30: plot: False
2025-09-25 12:30: prefix_boundary: True
2025-09-25 12:30: real_value: False
2025-09-25 12:30: rot_cap: 0.5
2025-09-25 12:30: roti_cap_scale: 0.7
2025-09-25 12:30: save_json: False
2025-09-25 12:30: save_pretrain_path: new_pretrain_model.pth
2025-09-25 12:30: scaler_zeros: 0.0
2025-09-25 12:30: scaler_zeros_day: 0
2025-09-25 12:30: scaler_zeros_week: 0
2025-09-25 12:30: scheduler: none
2025-09-25 12:30: seed: 12
2025-09-25 12:30: seed_mode: True
2025-09-25 12:30: stride_horizon: False
2025-09-25 12:30: t_ref_sec: 7200.0
2025-09-25 12:30: target_model: generic
2025-09-25 12:30: tec_ref: 50.0
2025-09-25 12:30: test_ratio: 0.1
2025-09-25 12:30: tod: False
2025-09-25 12:30: up_epoch: 6, 8
2025-09-25 12:30: use_adv: True
2025-09-25 12:30: use_diffusion: True
2025-09-25 12:30: use_drivers: True
2025-09-25 12:30: use_pinn: True
2025-09-25 12:30: val_ratio: 0.1
2025-09-25 12:30: week_day: 7
2025-09-25 12:30: weight_decay: 0.0
2025-09-25 12:30: xavier: False
2025-09-25 12:30: year_split: True
2025-09-25 12:30: PPINN parameters added to optimizer.
predictor.end_conv_2.weight torch.Size([12, 512, 1, 1]) True
predictor.end_conv_2.bias torch.Size([12]) True
Total params num: 408888, Update params num: 408888
*****************Finish Parameter****************
============================scaler_mae_loss
Applying learning rate decay.
Creat Log File in:  /root/tecGPT/Output/GIMtec/GWN/20250925_123026_GIMtec_GWN_ori.log
2025-09-25 12:30: Train Epoch 1: 0/160 Loss: 16.690046 (running_avg: 16.690046)
2025-09-25 12:31: Train Epoch 1: 20/160 Loss: 6.454872 (running_avg: 11.942142)
