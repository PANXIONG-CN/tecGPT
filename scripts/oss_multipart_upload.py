#!/usr/bin/env python3
"""
OSS åˆ†ç‰‡å¹¶è¡Œä¸Šä¼ å·¥å…·
é€‚ç”¨äºå¤§æ–‡ä»¶ (>100MB) çš„å¿«é€Ÿä¸Šä¼ 
"""
import os, oss2, time
from concurrent.futures import ThreadPoolExecutor, as_completed
from oss2.models import PartInfo

class MultipartUploader:
    def __init__(self, bucket, part_size_mb=100, max_workers=4):
        self.bucket = bucket
        self.part_size = part_size_mb * 1024 * 1024  # è½¬æ¢ä¸ºå­—èŠ‚
        self.max_workers = max_workers
        
    def upload_part_worker(self, args):
        """å•ä¸ªåˆ†ç‰‡ä¸Šä¼ ä»»åŠ¡"""
        upload_id, key, part_num, data = args
        start = time.time()
        result = self.bucket.upload_part(key, upload_id, part_num, data)
        elapsed = time.time() - start
        size_mb = len(data) / (1024**2)
        speed = size_mb / elapsed if elapsed > 0 else 0
        print(f"  âœ“ Part {part_num}: {size_mb:.1f} MB uploaded in {elapsed:.1f}s ({speed:.1f} MB/s)")
        return PartInfo(part_num, result.etag)
    
    def upload_file(self, local_file, oss_key):
        """åˆ†ç‰‡å¹¶è¡Œä¸Šä¼ æ–‡ä»¶"""
        file_size = os.path.getsize(local_file)
        file_size_mb = file_size / (1024**2)
        
        print(f"ğŸ“¤ å¼€å§‹åˆ†ç‰‡ä¸Šä¼ :")
        print(f"   æœ¬åœ°æ–‡ä»¶: {local_file}")
        print(f"   OSS è·¯å¾„: {oss_key}")
        print(f"   æ–‡ä»¶å¤§å°: {file_size_mb:.1f} MB")
        print(f"   åˆ†ç‰‡å¤§å°: {self.part_size/(1024**2):.0f} MB")
        print(f"   å¹¶å‘æ•°: {self.max_workers}")
        
        # åˆå§‹åŒ–åˆ†ç‰‡ä¸Šä¼ 
        upload_id = self.bucket.init_multipart_upload(oss_key).upload_id
        
        # è¯»å–æ–‡ä»¶å¹¶åˆ†ç‰‡
        parts_args = []
        part_num = 1
        
        with open(local_file, 'rb') as f:
            while True:
                data = f.read(self.part_size)
                if not data:
                    break
                parts_args.append((upload_id, oss_key, part_num, data))
                part_num += 1
        
        total_parts = len(parts_args)
        print(f"   æ€»åˆ†ç‰‡æ•°: {total_parts}\n")
        
        # å¹¶è¡Œä¸Šä¼ 
        start_time = time.time()
        parts = []
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [executor.submit(self.upload_part_worker, args) 
                      for args in parts_args]
            
            for future in as_completed(futures):
                parts.append(future.result())
        
        # å®Œæˆåˆ†ç‰‡ä¸Šä¼ 
        parts.sort(key=lambda x: x.part_number)
        self.bucket.complete_multipart_upload(oss_key, upload_id, parts)
        
        elapsed = time.time() - start_time
        speed = file_size_mb / elapsed
        
        print(f"\nâœ… ä¸Šä¼ å®Œæˆ!")
        print(f"   æ€»è€—æ—¶: {elapsed:.1f} ç§’")
        print(f"   å¹³å‡é€Ÿåº¦: {speed:.2f} MB/s ({speed*8:.1f} Mbps)")
        print(f"   åŠ é€Ÿæ¯”: {self.max_workers * speed / 11.10:.1f}x")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # OSS é…ç½®
    ak = os.environ["OSS_ACCESS_KEY_ID"]
    sk = os.environ["OSS_ACCESS_KEY_SECRET"]
    endpoint = os.environ.get("OSS_ENDPOINT", "oss-accelerate.aliyuncs.com")
    bucket_name = os.environ["OSS_BUCKET"]
    
    auth = oss2.Auth(ak, sk)
    bucket = oss2.Bucket(auth, 'https://' + endpoint, bucket_name)
    
    # åˆ›å»ºä¸Šä¼ å™¨
    uploader = MultipartUploader(bucket, part_size_mb=200, max_workers=6)
    
    # ä¸Šä¼ æ–‡ä»¶
    # uploader.upload_file('/path/to/large_file.bin', 'oss_key')
    print("ä½¿ç”¨æ–¹æ³•:")
    print("  uploader.upload_file('/path/to/file', 'oss/path/file')")
